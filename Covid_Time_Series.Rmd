---
title: "Covid Time Series"
output: pdf_document
---

# Cleaning the data set (which it desperately needs)

```{r}
cnd <- read.csv("United_States_COVID-19_Cases_and_Deaths_by_State_over_Time.csv", header = T)
clt <- read.csv("United_States_COVID-19_County_Level_of_Community_Transmission_as_Originally_Posted.csv", header = T)

names(clt)[1] <- "state_name"

# Check for duplicated observations
sum(duplicated(cnd))
sum(duplicated(clt))

# Check for empty rows
sum(apply(cnd, 1, function(x) all(is.na(x))))
sum(apply(clt, 1, function(x) all(is.na(x))))

# Dimensions of Data Sets
dim(cnd) # Dim of cases and deaths by states
dim(clt) # Dim of county level transmission

# Summary statistics of data sets
summary(cnd)
summary(clt)

# Something is wrong. Despite the majority of variables in cnd being numerical by inspecting 
# them, they are labeled as character variables. I'll change that quickly.
cnd[, c(3:12)] <- sapply(cnd[, c(3:12)], function(x) as.numeric(gsub(",","",x)))

# Similarly, clt seems to have an issue with one of the variables being primarily being numeric
# but being counted as a character variable due to "suppressed" being a recurring element.
# So, I'll change the instances of "suppressed" to be -1 instead.
clt[, 5] <- gsub("suppressed", -1, clt[, 5])
clt[, 5] <- as.numeric(gsub(",", "", clt[, 5]))

# Finally, we just need the dates to register as the date class
cnd$誰..submission_date <- as.Date(cnd$誰..submission_date, format = "%m/%d/%Y")
clt$report_date <- as.Date(clt$report_date, format = "%Y/%m/%d")
```

# EDA

```
I primarily wanted to do this with Los Angeles and California in mind but I saw the amount 
of counties in the county transmission data set (clt) with "suppressed" in their cases 
variable and thought I would do a generalized exploratory data analysis just to see what is
going on there. Then it's back to what I was originally going to do.
```

```{r}
library(dplyr)
library(ggplot2)
library(lubridate)

suppressed <- clt %>%
  select(state_name, county_name, community_transmission_level, 
         cases_per_100K_7_day_count_change) %>%
  filter(cases_per_100K_7_day_count_change == -1)
head(suppressed, 10)
d <- which(duplicated(suppressed[, c(1, 2)]) == T)
suppressed <- suppressed[-d, ]
paste(dim(suppressed)[1], "unique counties that have chosen to suppress their own case counts.")

table_states <- sort(table(suppressed$state_name), decreasing = T) # Amount of counties suppressing data per state
table_states
barplot(head(table_states, 10), col = "red", las = 2, cex.main = 0.75, cex.lab = 0.75, cex.axis = 0.75,
        main = "Top 10 States with the Highest Amounts of Counties that Suppressed Data", ylab = "Total")

table_tlevel <- prop.table(table(suppressed$community_transmission_level)[-1])
table_tlevel <- table_tlevel[c(2, 3, 1, 4)]
table_tlevel
barplot(table_tlevel, col = c("green", "yellow", "orange", "red"), ylim = c(0, 0.5),
        xlab = "Transmission Levels", ylab = "Percentage", 
        main = "Transmission Level Percentage within Counties that Suppressed Data")

# Now we move onto the actual work
cali_clt <- clt %>%
  filter(state_name == "California")
cali_cnd <- cnd %>%
  filter(state == "CA")
cali_cnd[, 6] <- gsub("-", "", cali_cnd[, 6])
cali_cnd <- cali_cnd %>% arrange(誰..submission_date)
head(cali_cnd, 10)

cali_clt <- cali_clt[-which(cali_clt$cases_per_100K_7_day_count_change <= 0), ]
cali_clt <- cali_clt %>% arrange(report_date)
head(cali_clt, 10)
# Due to the strangeness of cali_clt's variable, particularly with 
# cases_per_100k_7_day_count_change, we'll only be using this data set to see
# the community transmission levels of counties in California that have recorded their
# cases and see how that looks like.
t_clt <- table(cali_clt$community_transmission_level)[c(2, 3, 1, 4)]
barplot(t_clt, col = c("green", "yellow", "orange", "red"),
        xlab = "Transmission Levels", ylab = "Percentage", 
        main = "Transmission Levels in California Counties since Aug. 16, 2021")
```

# The Forecast

```{r}
library(forecast)
cali_cnd$new_case <- as.numeric(cali_cnd$new_case)
county_weekly <- cali_cnd %>% group_by(week = cut(誰..submission_date, "week", start.on.monday = FALSE)) %>% summarise(value = sum(new_case))
county_weekly$week <- as.Date(county_weekly$week)

ggplot(data = county_weekly, aes(x = week, y = value)) +
  geom_line() +
  ggtitle("California Weekly Case Counts since Jan. 2020")

ts_weekly_cases <- ts(county_weekly[,2], start = decimal_date(ymd('2020-01-19')),
                      frequency = 52)

# Run ARIMA and create summary.
arima_model <- auto.arima(ts_weekly_cases)
summary(arima_model)
 
# Forecast the number of points required
data_forecast <- forecast(arima_model, 10)
print(data_forecast)
 
# Plot the forecast data.
plot(data_forecast, xlab = 'Week', ylab = 'Cases', ylim = c(0, 8e+05))
# Looks like there will be a bit more cases in the near future

# So is our forecast accurate. Not really, no forecast is 100% accurate, but we want
# to see if ARIMA can at least capture a trend, and to do that, we'll see if it
# predicts the peak around December 2021 and January 2022.

cw <- county_weekly[-c((dim(county_weekly[1]) - 24):dim(county_weekly)[1]), ]
ts_weekly_cases2 <- ts(cw[,2], start = decimal_date(ymd('2020-01-19')),
                      frequency = 52)
arima_model2 <- auto.arima(ts_weekly_cases2)
summary(arima_model2)
data_forecast2 <- forecast(arima_model2, 15)
plot(data_forecast2, xlab = 'Week', ylab = 'Cases', ylim = c(0, 8e+05))

# While the values aren't the same, the pattern is correct for the trend we
# see in rising covid cases in January 2022. Like previously mentioned, you
# can never have a model that 100% accurately predict the future but it can sure
# try to pick up the patterns at the very least.
```
